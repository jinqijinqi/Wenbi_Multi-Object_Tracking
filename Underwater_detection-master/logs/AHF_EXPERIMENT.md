## 实验记录
#### 艾宏峰

当前baseline模型最优配置如下：

|配置|设置|
|:---:|:---:|
|模型|Faster R-CNN + r50 + FPN + DCN|
|anchor_ratio|[0.2, 0.5, 1.0, 2.0, 5.0]|
|训练多尺度|[(4096, 800), (4096, 1200)]|
|测试尺度|(4096, 1000)|
|NMS|soft_nms (min_score=0.001, max_per_img = 100)|
|epoch|1x schedule (12 epochs)|
|steps|[8, 11]|
|fp16|未开启|
|score|0.46353357|
|MAP/MAP50/MAP75|0.500/0.851/0.536|
****
### 2020年3月11日
1. 实验1主要是研究**libra**：  

|实验|libra|MAP|MAP50|MAP75|score|loss|
|:---:|:---:|:---:|:---:|:---:|:---:|:---:|
|0|无|0.500|0.851|0.536|**0.4635**|0.24|
|1|有|0.509|0.855|0.558|0.4616|0.46|

**总结**：Libra的初衷是解决训练中样本层，特征层和目标层的不平衡问题。分数略低一点的原因可能是当前数据量和数据的现有特征决定了模型的上限，虽然Libra在验证集上表现好，但可能存在验证集过拟合嫌疑。建议后续先在数据上下工夫，再考虑提高模型的复杂度。
### 2020年4月3日

1.实验27基于实验19训练尺度修改为（4096，800），（4096，1400）。

| 实验 | 测试尺度                                |    线上分数    |
| :--: | --------------------------------------- | :------------: |
|  19  | (4096, 600), (4096, 800), (4096, 1000)  | **0.49229116** |
|  27  | (4096, 600), (4096, 1000), (4096, 1400) | **0.49281524** |

总结：增加短边尺寸能提高分数，猜测为小目标结果提升，后续将对测试尺度进行筛选。

### 2020年3月12日
1. 实验2主要是研究**allowed_border和neg_pos_ub**：  

|实验|allowed_border|neg_pos_ub|MAP|MAP50|MAP75|score|loss|
|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|
|0|0|-1|0.500|0.851|0.536|**0.4635**|0.24|
|2|-1|3|0.503|0.854|0.537|0.4629|0.26|

注：neg_pos_ub=-1是指RPN是不对‘负样本/正样本’比率作限制，而neg_pos_ub=3是指负样本数最多是正样本数3倍。allowed_border=0是指超过图片边界的anchor将会被忽略，allowed_border=-1是不忽略。  

**总结**：按mmdetection论文说法实验2会提高了AR，而且论文提到在靠近边界的GT目标能够在训练中有更多匹配正样本，此外，数据集上有些海产就在图片边缘附近，但最后这种配置并没有带来提升，猜想原因是之前加入了更小的anchor ratio，这样边缘目标也能被更好的召回，所以这么没有提升。

### 2020年3月13日
1. 实验3主要是研究**群内选手提供的方案**:  

|配置|设置|
|:---:|:---:|
|模型|Cascade R-CNN + ResNeXt101 + FPN |
|anchor_ratio|[0.5, 1.0, 2.0]|
|训练多尺度|[(4096, 600), (4096, 1000)]|
|测试多尺度|[(4096, 600), (4096, 800), (4096, 1000)]|
|NMS|soft_nms (min_score=0.0001, max_per_img = 200)|
|epoch|1x schedule (12 epochs)|
|steps|[8, 11]|
|fp16|开启|
|预训练模型|HTC|
|score|0.4841776|
|MAP50|0.867|

|实验|baseline|MAP50|score|loss|
|:---:|:---:|:---:|:---:|:---:|
|0|我们|0.851|0.4635|0.24|
|3|郑烨|0.867|**0.4836**|0.54|

**总结**：郑烨大大提高了模型复杂度。相比我们，他提供的方案中模型更复杂，图像尺度更大更多变，NMS更宽松，也因为如此运行时间更长，为此他开启了混合精度训练的方法（通过16位浮点数（FP16）进行深度学习模型训练，从而减少了训练深度学习模型所需的内存，同时由于FP16的运算比FP32运算更快，从而也进一步提高了硬件效率），后续实验暂时在该基础上扩展实验内容。

### 2020年3月15日
1. 实验4主要是研究**训练开启的翻转增强**:

|实验|水平翻转|垂直翻转|MAP|MAP50|MAP75|score|loss|
|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|
|3|开启|未开启|0.526|0.863|0.585|**0.4836**|0.54|
|4|开启|开启|0.514|0.855|0.565|0.4780|0.46|

注：翻转概率均为0.5。

**总结**：追加垂直翻转不能带来表现提升，可能是因为加入垂直翻转的训练集中场景与测试集正常采集场景有些不一致引起的。暂时后续**不考虑垂直翻转**。  

### 2020年3月16日
1. 实验5主要是研究**实例平衡增强 (Instance-Balanced Augmentation)**:

|实验|实例平衡增强|MAP|MAP50|MAP75|score|loss|
|:---:|:---:|:---:|:---:|:---:|:---:|:---:|
|3|未开启|0.526|0.863|0.585|**0.4836**|0.54|
|5|开启|0.516|0.856|0.570|0.4562|0.2070|

**总结**：由于原数据集存在类别不平衡问题（实例数量：海参4574，海胆18676，扇贝5554和海星5704），所以打算使用阿里之前提出的一个实例平衡增强方法去增强数据解决不平衡问题，首先先把原图放大1.5倍，然后用原图原始尺寸大小作为滑窗大小，以滑窗形式水平平均地移动三次，垂直平均地移动三次，最后1张图会得到9张相当于shift和scale后的增强图片。在滑动中发现如果不对滑动窗口做限制，会加重类别不平衡，因为海胆数量太多，且滑动结果会有很多单张只有一个扇贝的情况从而导致扇贝很多。因此对滑动窗口进行限制：滑动窗口内含海胆就不要该窗口，滑动窗口内仅有一个扇贝的不要要。最后增强数据和原数据合并后的实例数量是：海参13016，海胆18676，扇贝13287和海星12322。**虽然类别平衡许多了且该增强模仿了水下手持拍摄设备从远到近的拍摄过程，但结果反而下降，原因是单纯的实例平衡增强其实有点像重复数据集操作**，这一点在‘第一个epoch下验证集比之前实验都高，在第9个epoch验证集表现最好’能反映出来，但是图片并没有很大的变化，最多是解决了模型平移不变性的问题。阿里其实后面还对这些增强图片还加入了一种自动并行增强（Auto Affine Augmentation）方法，即旋转边界框，白平衡，按照x轴或y轴截断等。这块后续有时间可以尝试下。

2. 今天对数据再次深入研究了下，有以下发现：  
- 宽高比1.22的2种采集图片像素低，放大易失真，且部分图片中目标及其密集，海产重叠严重。   
- 宽高比1.77的3中采集图片中，部分图片含有大量密集的扇贝目标或海胆目标（猜测是不同海产放养区所致）。  
- 图片有很多漏标，少扇贝区域的地方即使出现扇贝，也不太会被认真标注，而且因为被沙掩盖部分外壳，标注存在不确定性。而海参由于肉眼本身因海水可见度，辨别难度导致存在一定的漏标。一般从上拍下的海星不会被漏标，但是海底平行拍摄时容易被漏标。海胆漏标不严重，一般都是远处有小黑团的这种情况，可能不会被标注。  
- 数据集中无标注的图片是拍摄结束回到水面过程中记录的视频切片图。  
- 当前最优模型下，AP表现从大到小是：**海胆0.92 > 海星0.89 > 扇贝0.85 > 海参 0.80**。海胆检测好是因为标注数量多，特征（带刺）明显。海星第二好是因为海星大部分就是一个样，蓝绿角中间橘红色的特征，且一般属于大目标好检测。扇贝检测难度是沙土遮掩，标注不确定性大，小目标。海参难检测原因在于由于海水可见度低导致海参身上的触点较难观察到，而且颜色深沉，在海底环境中不突出，而且容易与条状石头，海洋生物排泄物或断落珊瑚，海草等混淆。

### 2020年3月17日
1. 实验6主要是研究**训练开启的模糊处理（MedianBlur或者Blur）**:

|实验|水平翻转|垂直翻转|MAP|MAP50|MAP75|score|loss|
|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|
|3|开启|未开启|0.526|0.863|0.585|**0.4836**|0.54|
|6|开启|未开启|0.524|0.862|0.584|**0.4837**|0.6386|

注：模糊概率均为0.1。

**总结**：模糊处理提升效果不大，可能是因为引入噪声引起的。后续**考虑增加模糊概率**。

### 2020年3月18日
1. 实验7主要是研究**训练使用retinex数据增强**:

|实验|retinex|MAP|MAP50|MAP75|海参|海胆|扇贝|海星|score|loss|
|:---:|:---:|:---:|:---:|:---:|:---:|-----|-----|-----|-----|-----|
|3|未开启|0.526|0.863|0.585|46.842|**52.548**|**55.064**|**55.929**|**0.4836**|0.54|
|7|开启|0.522|0.859|0.581|**47.105**|52.547|53.914|55.389|0.4830|0.5483|

注：dict(type='Retinex', model='MSR', sigma=[30, 150, 300], restore_factor=2.0, color_gain=6.0, gain=128.0, offset=128.0)  
**总结**：增强算法也有参数要调，对海参有所加强

### 2020年3月18日
1. 实验8主要是研究**训练开启one of(CLAHE+IAASharpen+IAAEmboss+RandomBrightnessContrast)**:

|实验|C|IAAS|IAAE|RBC|MAP|MAP50|MAP75|海参|海胆|扇贝|海星|score|loss|
|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|
|3|没|没|没|没|0.526|0.863|0.585|46.842|**52.548**|**55.064**|**55.929**|0.4836|0.54|
|8|有|有|有|有|0.526|0.866|0.586|**47.193**|52.331|54.785|55.887|**0.4853**|0.5617|

注：'CLAHE'对比度受限的自适应直方图均衡，clip_limit=2（对比度限制的上阈值）其他均为默认参数.。'IAAEmboss'，压印输入图像，并将结果与原始图像重叠。'IAASharpen'锐化输入图像，并将结果与原始图像重叠。其他均为默认参数.one of概率为0.3，内部概率方法均为0.5。

**总结**：将图像直方均匀和重叠处理对暗部目标有一定效果。后续**分别对四个方法进行深入分析**，经过各类的对比，可以发现通过处理的验证集只在海参的表现上高于baseline，故猜测海参这类对最终结果的影响较大，后续将针对海参这类的增强进行改进。


### 2020年3月19日
1. 实验9主要研究**泊松融合Poisson Blending数据增强**：

|实验|泊松融合|MAP|MAP50|MAP75|score|loss|
|:---:|:---:|:---:|:---:|:---:|:---:|:---:|
|3|未开启|0.526|0.863|0.585|**0.4836**|0.54|
|9|开启|0.508|0.851|0.558|未提交|0.52|

注：该对比实验组没加其他Albu手段。  
**总结**：在之前实验中发现海参检测效果差，受论文[UDD: An Underwater Open-sea Farm Object Detection Dataset for Underwater Robot Picking](https://arxiv.org/abs/2003.01446)启发：“海参和扇贝因为训练样本不足和数据类别不平衡问题导致很多模型表现不好”。因此实验7针对宽高为720和405的图片进行海参目标的数据增强工作（采用该尺寸的图片有两点原因：一是图片第二大，处理速度快不像第一大尺寸的图片，处理慢且耗内存。二是单独对这类图片融合后背景差异不会太大，避免融合突兀）。由于海参问题严重，所以只针对抠取了900多个海参，然后选取单图标注数量不超过4的图片作为融合海参的背景图片（单图过多标注可能会影响放置粘贴目标和带来冗余的目标加重类别不平衡问题）。之后根据融合后可视化结果将2616张增强图人工剔除剩1441张融合较好的图加入到原始数据集中进行训练。最后增强后各类别数据是：海参（4574变到6991），海胆（18676到20818），扇贝（5554到5653）和海星（5704到6326）。模型最后的表现并没有提升，即使是海参的AP也没增加，猜测原因是：融合的还是有些许不自然，容易使模型过拟合，而且这里并没有使用新的背景图片，而是原数据的图片，这也导致一些背景和目标重复出现，影响模型通用性的提升。

### 2020年3月20日
1. 实验10主要研究是**去除长短比为1.22的数据集**:

|实验|长短边1.22图|MAP|MAP50|MAP75|海参|海胆|扇贝|海星|score|loss|
|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|
|3|有|0.526|0.863|0.585|46.842|**52.548**|**55.064**|55.929|**0.4836**|0.52|
|10|无|0.526|0.863|0.590|**47.379**|52.199|54.587|**56.127**|未提交|0.49|

注：去除长短比为1.22的数据集是指不将（704,576）和（586,480）这两种尺寸图片（后续简称122图片）的加入到模型训练中。

**总结**: 经过进一步EDA发现：122图片与177图片是不同类设备采集得到的，而且训练集中122图片（共有82张）的各类别数量是：海参1个，海胆632个，扇贝和海星都是20个。而测试集图片尺寸情况如下：

|测试集图片尺寸（h,w）|长短边比|图片数量|
|:---:|:---:|:---:|
|(1080,1920)|1.77|42|
|(1440,2560)|1.77|32|
|**(1536,2048)**|**1.33**|**21**|
|(2160,3840)|1.77|653|
|(405,720)|1.77|52|

后面特意抽取看了长短边比为1.33的1536x2048图，发现其跟训练集122图片有些类似，猜测是同一类的设备，但是测试集中133图片（均为2018年拍摄）目测比训练集中122图（均为2017年拍摄）有更多的扇贝，且图片像素更大了，猜测是设备升级了。因为没有提交结果暂不下结论。  

## 2020年3月20日

实验11主要研究是**在3月18日的最佳得分上进行了全数据集训练**：

|实验|数据集|MAP|MAP50|MAP75|score|loss|
|:---:|:---:|:---:|:---:|:---:|:---:|:---:|
|8|训练集模型|0.526|0.866|0.586|**0.4853**|0.5617|
|11|全数据集模型|0.600|0.922|0.708|**0.4856**|0.54|

注：提升不大，说明训练集的分布基本囊括了验证集的分布

### 2020年3月21日
1. 实验12主要研究是**anchor_ratio增加0.2和allowed_border=-1**：

|实验|achor_ratio|allowed_border|MAP|MAP50|MAP75|score|loss|
|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|
|3|无0.2|0|0.526|0.863|0.585|**0.4836**|0.54|
|12|加0.2|-1|0.527|0.866|0.593|0.4819|0.62|

注：allowed_border=-1允许模型RPN在图片边缘提出超出边缘的框。

**总结**：虽然增强模型在边缘目标的表现能力和小目标检测能力在验证集上有提升，但提交结果反而下降了，猜测原因是由于测试集存在部分数据不属于训练集分布下，所以有可能实验10过拟合了验证集，后续实验应该注意提高模型通用性。

### 2020年3月22日
1. 实验13主要研究是**Motion Blurring**:

|MB|MAP|MAP50|MAP75|海参|海胆|扇贝|海星|score|loss|
|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|
|0|0.526|0.863|0.585|46.842|**52.548**|**55.064**|55.929|**0.4836**|0.54|
|0.3|0.522|0.863|0.575|**46.988**|52.177|53.780|**55.945**|未提交|0.56|

注：‘MB=0.3’是指训练时开启动态模糊Motion Blurring的概率为0.3。

**总结**：由于数据是视频拍摄某些连续帧下取得，因此拍摄设备的水下移动带来了动态模糊，为了模型在这种数据下获得更好的鲁棒性，在``mmdet/pipelines``下的``transforms.py``和``__init__.py``下添加了MotionBlur的数据增强手段。在验证集上，实验11在海参和海星上有所提高，但是海胆和扇贝反而下降，这个可能涉及到不同海产在这种画面模糊的在分布情况不一致，原因也暂不明晰。参考：2020年3月17日的MedianBlur（p=0.1）虽然验证集上表现不好，但最终结果有提升，需要注意的是实验11的动态模糊发生概率越大，验证集表现越差，所以实验11只是设置为0.3而不是常见的0.5。另外，实验11动态模糊充分考虑到不同尺寸的数据集原图而单独赋予不同的模糊核大小（(1) w<=750, 核大小为10-20; (2) 750<w<2000，核大小为20-60; (3) w>=2000, 核大小为100-140）。

### 2020年3月22日



2. 实验14主要研究的是**将虚警概率大的水草作为正样本，但不输出**

|实验|MAP|MAP50|MAP75|海参|海胆|扇贝|海星|score|loss|
|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|
|8| 0.526 | 0.866 | 0.586 | **47.193** | 52.331 | 54.785 | 55.887 |   0.4853   | 0.5617 |
|14| 0.570 | 0.879 | 0.673 |            |        |        |        | **0.4922** | 0.5397 |

注：该实验使用的是**全数据集**



### 2020年3月23日

1. 实验15主要研究是**IAAsharpen**:

|实验|S|MAP|MAP50|MAP75|海参|海胆|扇贝|海星|score|loss|
|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|
|3|0|0.526|0.863|0.585|46.842|**52.548**|**55.064**|55.929|**0.4836**|0.54|
|15|0.5|0.525|0.865|0.583|**47.182**|52.343|54.517|**55.959**|未提交|0.5551|

注：‘S=0.5’是指训练时开启IAAsharpen的概率为0.5。  
**总结**：锐化重叠对海参和海星类有提升，但对海胆和扇贝却降低，具体原因还得深入分析。



### 2020年3月24日

实验16主要在实验14的基础上，**将验证集和训练集分开了**

|实验|MAP|MAP50|MAP75|海参|海胆|扇贝|海星|score|loss|
|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|
|8| **0.526** | **0.866** | **0.586** | 47.193 | 52.331 | **54.785** | **55.887** |   0.4853   | 0.5617 |
|11|   0.600   |   0.922   |   0.708   |            |            |            |  | **0.4856** | 0.54 |
|16|   0.460   |   0.783   |   0.491   | **47.557** | **52.404** | 54.412 | 55.844 | 0.4857 |0.5483 |
|14| 0.570 | 0.879 | 0.673 |  |  |  |  | **0.4922** | 0.5397 |

实验16仅仅拆开了验证和训练，但是降低了很多点，主要怀疑是因为实验16每张图的测试max_per_img=200，实验14每张图的max=300，实验14提高了测试时的查全率，其实模型的性能本质没有改变，map表现提高。

| 类别 | 验证集ann数量 |
| ---- | ------------- |
| 海参 | 963           |
| 海胆 | 3667          |
| 扇贝 | 1166          |
| 海星 | 1137          |
| 水草 | 12            |

| 类别 | 训练集ann数量 |
| ---- | ------------- |
| 海参 | 4574          |
| 海胆 | 3667          |
| 扇贝 | 5554          |
| 海星 | 5704          |
| 水草 | 70            |

- 实验8、11的未加水草的数据集与实验16、14加水草的数据集，除水草外，其余数据完全一致。

- 一些黑乎乎的阴影，实验11检测为海胆，实验14正确检测。

- 实验11检测不到的扇贝，实验14正确检测。

- 实验14将水草认成海胆海参机率提高。

- 实验14对扇贝提升效果很高。

### 2020年3月25日
1. 实验17主要研究是**dcn**的表现
实验18主要研究是**seresnext101**的表现:

| 实验 |  MAP  | MAP50 | MAP75 |    海参    |    海胆    |  扇贝  |    海星    | score  |  loss  |
| :--: | :---: | :---: | :---: | :--------: | :--------: | :----: | :--------: | :----: | :----: |
|  16  | 0.460 | 0.783 | 0.491 | **47.557** | 52.404 | **54.412** |   55.844   | 0.4857 | 0.5397 |
|  17  | 0.500 | 0.807 | 0.536 |   47.190   | **53.773** | 53.696 |   56.017   | 0.4776 | 0.3818 |
|  18  | 0.483 | 0.816 | 0.504 |   46.967   |   53.537   | 53.716 | **56.085** | 未提交 | 0.4690 |


**总结**：猜测dcn使模型过拟合，seresnext101的速度比baseline快2-3倍，最终的模型选取，可以在速度上权衡使用seresnext101。

### 2020年3月25日
1. 实验18主要研究的是在实验14的基础上添加mixup

|实验|MAP|MAP50|MAP75|海参|海胆|扇贝|海星|score|loss|
|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|
|18| 0.507 | 0.796 | 0.580|  |  |  |  | 0.4819 | 0.7826 |
|14| 0.570 | 0.879 | 0.673 |  |  |  |  | **0.4922** | 0.5397 |

### 2020年3月26日
1.实验19，主要研究在实验14的基础上放开max_per_num = 1000
|实验|MAP|MAP50|MAP75|海参|海胆|扇贝|海星|score|loss|
|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|
|19| 0.570 | 0.879 | 0.673 |  |  |  |  | **0.49229116** | 0.5397 |
|14| 0.570 | 0.879 | 0.673 |  |  |  |  | 0.49222164 | 0.5397 |

- 实验19max_per_img=5000，有26w个标注结果，去掉水草2万个标注结果，还剩24万个标注结果，'240720/800=301框/图， 301/4=75.25框/类。  
- 实验14max_per_img=300，有20W个标注结果。  
- 实验16max_per_img=200，有14W个标注结果，单图每类平均有50个框。 

### 2020年3月27日
1. 实验20主要研究的是**追加海草难样本标注**下模型的表现：

|实验|MAP|MAP50|MAP75|海参|海胆|扇贝|海星|score|loss|
|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|
|19| 0.570 | 0.879 | 0.673 |  |  |  |  | **0.49229116** | 0.5397 |
|20|   |  |  |  |  |  |  | 0.48268375 | 0.5097 |

注：实验19和20均为带海草的全数据集训练得到的结果，且max_per_img=5000。

**总结**：在实验14的结果可视化发现2020年3月24日几个问题，由于海草在全数据集上只有82个标注且很多海草并没有被认真标注，且存在海草被误认做海胆和海参，对此的猜测是海草标注不清楚带来了模型辨认上的困难。为了清除这个遗漏，我们先将当前最优模型预测训练集并可视化框在图上，之后将训练集中被误检成其他类且无标注的海草目标进行框的绘制，之后补充到原数据集中，5千多张图最后补充了额外800多个海草标注，提交结果比实验19少了5w的标注。但最后模型提交结果并不是很好，可能是因为在减少误检和提高查全率（即检测出更多框）之间，mAP在此数据上更加偏向于后者。

2. @郑烨选手更新了Github，有几点内容需要留意下：
- 最近很多选手分突然上了0.49，应该是得益于选手分享的：**res50和se50均可以达到线上testA 46-47 mAP, 经过spytensor试验进行模型集成可以达到49+。** 在论文《Weighted Boxes Fusion: ensembling boxes for object detection models》里提到两种模型融合思路，一种是**同一模型不同backbone的融合（也是其他选手@spytensor的推荐，且建议使用WBF（IOU=0.7））**， 第二种是**不同结构的模型进行融合，根据论文所述这种方法比前者提升更大**。WBF的代码开源地址：[https://github.com/ZFTurbo/Weighted-Boxes-Fusion](https://github.com/ZFTurbo/Weighted-Boxes-Fusion)。建议后面实验使用看看。  
- @郑烨有一些不work的内容，大部分我们都试过，但有几点需要后面留意下：**引入往年数据**(2020年3月20日的实验10我们就有做过，但是没提交所以也不确定结果会怎样)，**se154与x101接近**(那能不能考虑进模型融合当中？)，**高分的fp： 相当多一部分是标注漏标错标造成，例如训练集存在相邻帧图片同一目标前一帧标注，后一帧不标情况，例如对于较为模糊的目标是否标注也很不统一**(之前试过通过人工标注解决这个问题，但标注量是在太大了，且画面移动后模糊情况不一样，很难采用统一的标注标准)，**低分的tp： 这一类主要集中在模糊目标上，模型整体对模糊目标预测的score较低，但是数据的标注对于模糊对象标准并不一致**(与前面一点也有谈及这个问题，之前有做过MedianBlur和MotionBlur的实验，前者提升很小很小，后者因验证集无明显提升所以没提交，怎么解决模糊对象标注标准不一致的问题也是该留意的问题)。

### 2020年3月29日
1. 实验21和22主要研究的是**Weighted Boxes Fusion (WBF)**:

|实验|模型|MAP|MAP50|MAP75|海参|海胆|扇贝|海星|score|loss|
|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|
|19|x101| 0.570 | 0.879 | 0.673 |  |  |  |  | **0.49229116** | 0.5397 |
|21|x101+s50||  |  |  |  |  |  | 0.47551257||
|22|x101+r50|| |  |  |  |  |  | 0.46915054||

注：这里三个实验均使用baseline模型，只是backbone不同，实验21融合的是senet50，实验22是融合resnet50。在模型结果融合中：当前最优下x101模型给予权重2，而s50和r50的权重为1，框匹配判定的IOU是0.7（作者是0.55）。

**总结**：结果都不好，猜测有以下几个变量需要在验证集上进行测试后再提交比较稳当：  

|测试编号|模型(w,albu)    |次模型(w,albu)    |主模型带海草|次模型带海草|IOU       | nms    |验证集mAP|海参   |海胆  |扇贝   |海星   |
|:-----:|:-------------:|:---------------:|:--------:|:--------:|:--------:|:------:|:------:|:----:|:----:|:----:|:----:|
| 1     | x101(1,✓)     | s50(1,✗)        |  ✓       | ✗        | 0.7      | nms+avg| 0.517  |46.855|51.130|53.772|54.859|
| 2     | x101(1,✓)     | s50(1,✗)        |  ✓       | ✗        | 0.5      | nms+avg| 0.513  |46.294|50.821|53.477|54.686|
| 3     | x101(1,✓)     | s50(1,✗)        |  ✓       | ✗        | 0.7      |soft+max| 0.518  |46.925|51.622|53.857|54.937|
| 4     | x101(1,✓)     | s50(1,✗)        |  ✓       | ✗        | 0.5      |soft+max| 0.513  |46.327|50.686|53.549|54.669|


对于WBF的一些发现和思考：
- WBF融合分为两块：框和置信度。各自聚类匹配框和其置信度的融合权重是score × weight。
- 如果WBF是在softNMS的结果上做融合，会因为某目标上**存在冗余低分框拉低融合后的框分数，而框的位置也是平均了冗余框得到**。解决方法有两个：  
 （1）使用论文的方法，**使用NMS输出的结果上实施WBF,@spytensor推荐NMS的score_thr=0.001**，这样NMS只是保留当前模型下唯一的高分框，这样最后平均融合后不会受冗余低分框影响。  
 （2）**在softNMS下，改置信度融合方法conf_type为max**，这样在两个模型预测结果中选择其中最大的置信度作为平均融合框的置信度。
 - 以上两种方法中，框坐标的融合都是采用score x weight然后平均的方式，只是置信度不一样，前者使用avg(NMS)，后者max(SoftNMS)。需要注意的是以上两种方法不建议使用weights=[2,1]，因为如果一个框0.9,一个框1.0，最后融合conf=(0.9x2+1.0)=1.4>1.0，分数会不正常。因此后续**推荐使用weights=[1,1]**。

2. 实验23主要研究的是**softNMS + WBF**:

|实验|模型|conf_type|MAP|MAP50|MAP75|海参|海胆|扇贝|海星|score|loss|
|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|
|19|x101|-| 0.570 | 0.879 | 0.673 |  |  |  |  | **0.49229116** | 0.5397 |
|21|x101+s50|avg||  |  |  |  |  |  | 0.47551257||
|23|x101+s50|max||  |  |  |  |  |  | 0.49188273||

注：实验23是采用基于SoftNMS结果的基础上，conf_type='max', weights=[1,1]和iou_thr = 0.7的配置。而实验21是SoftNMS+conf_type='avg', weights=[2,1]和iou_thr = 0.7。

**总结**：在‘对于WBF的一些发现和思考’中的发现是正确的，后期建议可以采用解决方法（1）试试。

### 2020年3月31日
1. 实验24主要研究的是**建海参专家模型并WBF结果融合**

|实验|模型|conf_type|MAP|MAP50|MAP75|海参|海胆|扇贝|海星|score|loss|
|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|
|19|x101|-| 0.570 | 0.879 | 0.673 |  |  |  |  | **0.49229116** | 0.5397 |
|24|x101+r101|max| - | - | - |  |  |  |  | 0.49051643 |- |

注：实验24最后的结果是‘x101其他类别结果保留 + x101模型下海参结果和r101海参专家模型下海参结果进行Softnms max的WBF’。

**总结**:x101模型下海参框的数量是120596个，而x101模型下海参数量是55041，融合后海参数量为120847。最后结果并不好。
### 2020年4月1日
1.实验25，26均使用了albu增强。
|实验|模型|conf_type|MAP|MAP50|MAP75|
|:---:|:---:|:---:|:---:|:---:|:---:|
|25|x101|-| 0.4560 | 0.7800 | 0.481 |
|26|fasterrcnn|-| 0.461 | 0.785 | 0.498 | 
|27|r101|-| 0.467 | 0.791 | 0.509 | 

### 2020年4月3日

1.实验27基于实验19训练尺度修改为（4096，800），（4096，1400）。

| 实验 | 测试尺度                                |    线上分数    |
| :--: | --------------------------------------- | :------------: |
|  19  | (4096, 600), (4096, 800), (4096, 1000)  | 0.49229116|
|  27  | (4096, 600), (4096, 1000), (4096, 1400) | **0.49281524** |

**总结**：猜测增加训练尺度能提高小目标的检测精度，后期将对测试尺度再深入的分析实验一下。

### 2020年4月4日

1.实验28基于实验27添加了guided-anchoring模块。
在实验27的第12个epoch上，使用学习率0.002,0.0002，0.00002进行finetune了3个epoch

|实验|MAP|MAP50|MAP75| 测试尺度 |score|loss|
|:---:|:---:|:---:|:---:|:---:|:---:|:---:|
|27| 0.544 | 0.847 | 0.647| (4096, 600),(4096, 1400)  | 0.49281524 | 0.5147 |
|28| 0.551 | 0.859 | 0.632 | (4096, 600),(4096, 1200) | 0.48914663 | 0.8240 |            

ga模块需要占用现存，训练缩放到1400，GPU显存会炸，只能缩放到1200

**总结**：损失一直没有降下来，训练尺度小，可能ga的损失本来就略高，finetune了3个epoch并没有效果

### 2020年4月8日
1. 实验29主要研究的是**cosine lr decay**：

|实验|lr_decay_type|score|
|:---:|:---:|:---:|
|19|step|**0.49229116**|
|29|cosine|0.48785642|

**总结**：从训练日志的损失图来看，收敛地更好，但也可能因此导致了过拟合使得模型在测试集上表现下降。

### 2020年4月9-10日
1. 实验30和31主要研究的是**label smoothing标签平滑**：

|实验|lr_decay|label_smoothing|score|
|:---:|:---:|:---:|:---:|
|27|step|无|0.49281524|
|30|cosine|0.005|0.49232983|
|31|step|0.001|0.49232983|

注：label_smoothing下的数是指平滑指数，它越高，平滑效果越大。  

### 2020年4月11日
1. 实验32主要研究的是**albu**：

|实验|albu概率|score|
|:---:|:---:|:---:|
|27|0.3|0.4700782|
|30|0.5|0.47165024|

注：这里的ablu是使用的one of(CLAHE+IAASharpen+IAAEmboss+RandomBrightnessContrast)，而score为B榜测试集数据上的表现。
